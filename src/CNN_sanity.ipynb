{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN implementation sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname('.'), '../lib/'))\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_relu_pool\n",
      "dx error:  6.7683903969e-08\n",
      "dw error:  5.55870956529e-10\n",
      "db error:  6.08701748165e-11\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import conv_relu_pool_forward, conv_relu_pool_backward\n",
    "\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = conv_relu_pool_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], b, dout)\n",
    "\n",
    "print 'Testing conv_relu_pool'\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dw error: ', rel_error(dw_num, dw)\n",
    "print 'db error: ', rel_error(db_num, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check loss\n",
    "After you build a new network, one of the first things you should do is sanity check the loss. When we add regularization this should go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss (no regularization):  15.454349761\n",
      "Initial loss (with regularization):  720.449650054\n"
     ]
    }
   ],
   "source": [
    "model = ThreeLayerConvNet(input_dim=(1, 96, 96), num_filters=32, filter_size=7,\n",
    "               hidden_dim=100, num_outputs=15, weight_scale=1e-3, reg=0.0,\n",
    "               dtype=np.float32)\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 1, 96, 96)\n",
    "y = np.random.randn(N, 15)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print 'Initial loss (no regularization): ', loss\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print 'Initial loss (with regularization): ', loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient check\n",
    "After the loss looks reasonable, use numeric gradient checking to make sure that your backward pass is correct. When you use numeric gradient checking you should use a small amount of artifical data and a small number of neurons at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x max relative error: 2.132175e-09\n"
     ]
    }
   ],
   "source": [
    "# Gradient check for l2_loss implementation\n",
    "num_outputs = 30\n",
    "\n",
    "x = np.random.randn(num_outputs)\n",
    "y = np.random.randn(num_outputs)\n",
    "\n",
    "loss, dx = l2_loss(x, y)\n",
    "\n",
    "f = lambda _: l2_loss(x, y)[0]\n",
    "param_grad_num = eval_numerical_gradient(f, x, verbose=False, h=1e-6)\n",
    "e = rel_error(param_grad_num, dx)\n",
    "print '%s max relative error: %e' % ('x', e)\n",
    "\n",
    "assert e < 1e-7, 'L2 Loss function gradient check fail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 max relative error: 3.380814e-08\n",
      "W2 max relative error: 2.885083e-04\n",
      "W3 max relative error: 9.692636e-06\n",
      "b1 max relative error: 1.935541e-09\n",
      "b2 max relative error: 7.107249e-10\n",
      "b3 max relative error: 4.525879e-07\n"
     ]
    }
   ],
   "source": [
    "# Gradient check for model.loss\n",
    "\n",
    "num_inputs = 2\n",
    "input_dim = (1, 16, 16)\n",
    "reg = 0.0\n",
    "num_outputs = 30\n",
    "X = np.random.randn(num_inputs, *input_dim)\n",
    "y = np.random.randn(num_inputs, num_outputs)\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters=3, filter_size=3,\n",
    "                          input_dim=input_dim, hidden_dim=7,\n",
    "                          num_outputs=num_outputs, loss_fn=l2_loss,\n",
    "                          dtype=np.float64, weight_scale=1e-2,\n",
    "                        )\n",
    "loss, grads = model.loss(X, y)\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print '%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit small data\n",
    "A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../data/train_data_cleaned.npz\n",
      "loaded:  ['X_train_clean', 'y_train_miss', 'X_train_miss', 'y_train_clean']\n"
     ]
    }
   ],
   "source": [
    "# Load previously cleaned data\n",
    "\n",
    "import os\n",
    "\n",
    "np_loaded_data_file = '../data/train_data_cleaned.npz'\n",
    "if not os.path.isfile(np_loaded_data_file):\n",
    "    print \"%s does not exist. See facial_recog_kaggle.ipynb\" % np_loaded_data_file\n",
    "else:\n",
    "    print \"loading %s\" % np_loaded_data_file\n",
    "    npzfile = np.load(np_loaded_data_file)\n",
    "    print \"loaded: \", npzfile.files\n",
    "    X_train_clean, y_train_clean = npzfile['X_train_clean'], npzfile['y_train_clean']\n",
    "    X_train_miss, y_train_miss = npzfile['X_train_miss'], npzfile['y_train_miss']\n",
    "    \n",
    "\n",
    "        \n",
    "num_train = 100\n",
    "num_val = 25\n",
    "\n",
    "rand_idx = np.random.choice(num_train + num_val, num_train + num_val, replace=False)\n",
    "X_train_small = X_train_clean[rand_idx[:num_train]]\n",
    "y_train_small = y_train_clean[rand_idx[:num_train]]\n",
    "\n",
    "X_val_small = X_train_clean[rand_idx[num_train:num_train + num_val]]\n",
    "y_val_small = y_train_clean[rand_idx[num_train:num_train + num_val]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 50) loss: 77018.905935\n",
      "(Epoch 0 / 25) train acc: 1824518.288158; val_acc: 1713562.670942\n",
      "(Iteration 2 / 50) loss: 55615635.589465\n",
      "(Epoch 1 / 25) train acc: 10270.545054; val_acc: 10073.332921\n",
      "(Iteration 3 / 50) loss: 301865.636003\n",
      "(Iteration 4 / 50) loss: 339079.763492\n",
      "(Epoch 2 / 25) train acc: 2583.598248; val_acc: 2562.729730\n",
      "(Iteration 5 / 50) loss: 77524.112346\n",
      "(Iteration 6 / 50) loss: 78409.651633\n",
      "(Epoch 3 / 25) train acc: 2583.284481; val_acc: 2562.417149\n",
      "(Iteration 7 / 50) loss: 77589.155097\n",
      "(Iteration 8 / 50) loss: 77611.401969\n",
      "(Epoch 4 / 25) train acc: 2583.140154; val_acc: 2562.273190\n",
      "(Iteration 9 / 50) loss: 77481.715784\n",
      "(Iteration 10 / 50) loss: 77274.002809\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c7047e9f5837>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m                 },\n\u001b[0;32m     18\u001b[0m                 verbose=True, print_every=1)\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Projects\\kaggle_facial\\facial_keypoint_recognition\\lib\\cs231n\\solver.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mfirst_it\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlast_it\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mepoch_end\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         train_acc = self.check_accuracy(self.X_train, self.y_train,\n\u001b[1;32m--> 265\u001b[1;33m                                         num_samples=1000)\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_acc_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Projects\\kaggle_facial\\facial_keypoint_recognition\\lib\\cs231n\\solver.pyc\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[1;34m(self, X, y, num_samples, batch_size)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized solver type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"classification\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m       \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\numpy\\core\\shape_base.pyc\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \"\"\"\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m     \u001b[1;31m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "small_data = {\n",
    "  'X_train': X_train_small,\n",
    "  'y_train': y_train_small,\n",
    "  'X_val': X_val_small,\n",
    "  'y_val': y_val_small,\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters=32, filter_size=3,\n",
    "                          loss_fn=l2_loss,\n",
    "                          dtype=np.float64, weight_scale=1e-3)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=25, batch_size=50,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-6,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

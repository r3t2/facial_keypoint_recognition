{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN implementation sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname('.'), '../lib/'))\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_relu_pool\n",
      "dx error:  9.69117719256e-09\n",
      "dw error:  1.74442857221e-09\n",
      "db error:  4.30071778386e-11\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import conv_relu_pool_forward, conv_relu_pool_backward\n",
    "\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = conv_relu_pool_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], b, dout)\n",
    "\n",
    "print 'Testing conv_relu_pool'\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dw error: ', rel_error(dw_num, dw)\n",
    "print 'db error: ', rel_error(db_num, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check loss\n",
    "After you build a new network, one of the first things you should do is sanity check the loss. When we add regularization this should go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss (no regularization):  16.388273905\n",
      "Initial loss (with regularization):  776.871306132\n"
     ]
    }
   ],
   "source": [
    "model = ThreeLayerConvNet(input_dim=(1, 96, 96), num_filters=32, filter_size=7,\n",
    "               hidden_dim=100, num_outputs=15, weight_scale=1e-3, reg=0.0,\n",
    "               dtype=np.float32)\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 1, 96, 96)\n",
    "y = np.random.randn(N, 15)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print 'Initial loss (no regularization): ', loss\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print 'Initial loss (with regularization): ', loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient check\n",
    "After the loss looks reasonable, use numeric gradient checking to make sure that your backward pass is correct. When you use numeric gradient checking you should use a small amount of artifical data and a small number of neurons at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 max relative error: 6.586571e-08\n",
      "W2 max relative error: 1.984268e-05\n",
      "W3 max relative error: 1.226340e-05\n",
      "b1 max relative error: 1.108325e-08\n",
      "b2 max relative error: 1.061583e-09\n",
      "b3 max relative error: 3.942324e-08\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "input_dim = (1, 48, 48)\n",
    "reg = 0.0\n",
    "num_outputs = 30\n",
    "X = np.random.randn(num_inputs, *input_dim)\n",
    "y = np.random.randn(num_inputs, num_outputs)\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters=3, filter_size=3,\n",
    "                          input_dim=input_dim, hidden_dim=7,\n",
    "                          num_outputs=num_outputs, loss_fn=l2_loss,\n",
    "                          dtype=np.float64, weight_scale=1e-2,\n",
    "                        )\n",
    "loss, grads = model.loss(X, y)\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print '%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit small data\n",
    "A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load previously cleaned data\n",
    "\n",
    "import os\n",
    "\n",
    "np_loaded_data_file = '../data/train_data_cleaned.npz'\n",
    "if not os.path.isfile(np_loaded_data_file):\n",
    "    print \"%s does not exist. See facial_recog_kaggle.ipynb\" % np_loaded_data_file\n",
    "else:\n",
    "    print \"loading %s\" % np_loaded_data_file\n",
    "    npzfile = np.load(np_loaded_data_file)\n",
    "    print \"loaded: \", npzfile.files\n",
    "    X_train_clean, y_train_clean = npzfile['X_train_clean'], npzfile['y_train_clean']\n",
    "    X_train_miss, y_train_miss = npzfile['X_train_miss'], npzfile['y_train_miss']\n",
    "    \n",
    "\n",
    "        \n",
    "num_train = 100\n",
    "num_val = 25\n",
    "\n",
    "rand_idx = np.random.choice(num_train + num_val, num_train + num_val, replace=False)\n",
    "X_train_small = X_train_clean[rand_idx[:num_train]]\n",
    "y_train_small = y_train_clean[rand_idx[:num_train]]\n",
    "\n",
    "X_val_small = X_train_clean[rand_idx[num_train:num_train + num_val]]\n",
    "y_val_small = y_train_clean[rand_idx[num_train:num_train + num_val]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_data = {\n",
    "  'X_train': X_train_small,\n",
    "  'y_train': y_train_small,\n",
    "  'X_val': X_val_small,\n",
    "  'y_val': y_val_small,\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvNet(weight_scale=1e-2)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-5,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

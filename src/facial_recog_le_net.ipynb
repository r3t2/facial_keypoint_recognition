{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mily/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "caffe_root = '../../../caffe/'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../data/train_data_cleaned.npz\n",
      "loaded:  ['X_val_clean_cv', 'y_val_clean_cv', 'y_train_clean_cv', 'feature_labels', 'X_train_clean_cv']\n",
      "(1628, 1, 96, 96) (1628, 30)\n",
      "(512, 1, 96, 96) (512, 30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "np_loaded_data_file = '../data/train_data_cleaned.npz'\n",
    "if not os.path.isfile(np_loaded_data_file):\n",
    "    print \"%s does not exist. See facial_recog_kaggle.ipynb\" % np_loaded_data_file\n",
    "else:\n",
    "    print \"loading %s\" % np_loaded_data_file\n",
    "    npzfile = np.load(np_loaded_data_file)\n",
    "    print \"loaded: \", npzfile.files\n",
    "    X_train_clean_cv, y_train_clean_cv = npzfile['X_train_clean_cv'], npzfile['y_train_clean_cv']\n",
    "    X_val_clean_cv, y_val_clean_cv = npzfile['X_val_clean_cv'], npzfile['y_val_clean_cv']\n",
    "    feature_labels = npzfile['feature_labels']\n",
    "    print X_train_clean_cv.shape, y_train_clean_cv.shape\n",
    "    print X_val_clean_cv.shape, y_val_clean_cv.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__b_lr_5.41e-04__reg_param_4.64e-03__batch_size_64__drop_5.00e-01_201610231643\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "td_size = ( X_train_clean_cv.shape[0] // batch_size) * batch_size\n",
    "# print td_size\n",
    "# td_size = 256\n",
    "val_data_size, num_labels = y_val_clean_cv.shape\n",
    "\n",
    "\n",
    "# val_data_size = 2*batch_size\n",
    "\n",
    "\n",
    "#Define all params for training\n",
    "DEBUG_MSGS = 0\n",
    "dropout_ratio = 0.5\n",
    "num_epochs = 10\n",
    "min_epochs = 50\n",
    "auto_stop = False\n",
    "\n",
    "base_lr = 5.41e-4\n",
    "stepsize_in_epoch = 25 #drop learning rate once every stepsize_in_epoch epochs\n",
    "stepsize = (td_size // batch_size) * stepsize_in_epoch\n",
    "gamma = 0.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reg_param = 4.641589e-03\n",
    "\n",
    "\n",
    "train_suffix = \"__b_lr_%.02e__reg_param_%0.02e__batch_size_%d__drop_%.02e_\" % (base_lr, reg_param, batch_size, dropout_ratio)\n",
    "train_suffix = train_suffix + time.strftime(\"%Y%m%d%H%M\")\n",
    "print train_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L, params as P\n",
    "\n",
    "def lenet(hdf5_list, batch_size=64, dropout_ratio=0.5, train=True):\n",
    "    # our version of LeNet: a series of linear and simple nonlinear transformations\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    n.data, n.label = L.HDF5Data(batch_size=batch_size, source=hdf5_list, ntop=2)\n",
    "    \n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=3, num_output=32, weight_filler=dict(type='xavier'), bias_filler=dict(type='constant', value=0.1))\n",
    "    n.relu1 = L.ReLU(n.conv1, in_place=False, relu_param=dict(negative_slope=0.1))\n",
    "    n.pool1 = L.Pooling(n.relu1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.bn1   = L.BatchNorm(n.pool1, batch_norm_param=dict(use_global_stats = (train==False)))\n",
    "    \n",
    "    n.conv2 = L.Convolution(n.bn1, kernel_size=3, num_output=64, weight_filler=dict(type='xavier'), bias_filler=dict(type='constant', value=0.1))\n",
    "    n.relu2 = L.ReLU(n.conv2, in_place=False, relu_param=dict(negative_slope=0.1))\n",
    "    n.pool2 = L.Pooling(n.relu2, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    \n",
    "    \n",
    "#     if train:\n",
    "    n.drop3 = fc1_input = L.Dropout(n.pool2, in_place=True, dropout_param = dict(dropout_ratio=dropout_ratio) )\n",
    "#     else:\n",
    "#         fc1_input = n.pool2\n",
    "            \n",
    "    n.fc1 =   L.InnerProduct(n.drop3, num_output=500, weight_filler=dict(type='xavier'), bias_filler=dict(type='constant', value=0.1))\n",
    "    n.relu3 = L.ReLU(n.fc1, in_place=True, relu_param=dict(negative_slope=0.1))\n",
    "    n.score = L.InnerProduct(n.relu3, num_output=30, weight_filler=dict(type='xavier'))\n",
    "    n.loss =  L.EuclideanLoss(n.score, n.label)\n",
    "    \n",
    "    return n.to_proto()\n",
    "\n",
    "train_net_path = 'train_net' + train_suffix + '.prototxt'\n",
    "train_net_path_test_time = 'train_net_test_time' + train_suffix + '.prototxt'\n",
    "test_net_path = 'test_net' + train_suffix + '.prototxt'\n",
    "\n",
    "with open(train_net_path, 'w') as f:\n",
    "    f.write(str(lenet(hdf5_list='../data/train_hdf5.list', batch_size=batch_size, dropout_ratio=dropout_ratio, train=True)))\n",
    "    \n",
    "with open(train_net_path_test_time, 'w') as f:\n",
    "    f.write(str(lenet(hdf5_list='../data/train_hdf5.list', batch_size=batch_size, dropout_ratio=dropout_ratio, train=False)))\n",
    "    \n",
    "with open(test_net_path, 'w') as f:\n",
    "    f.write(str(lenet(hdf5_list='../data/test_hdf5.list', batch_size=batch_size, dropout_ratio=dropout_ratio, train=False)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from caffe.proto import caffe_pb2\n",
    "s = caffe_pb2.SolverParameter()\n",
    "\n",
    "# Set a seed for reproducible experiments:\n",
    "# this controls for randomization in training.\n",
    "s.random_seed = 0xCAFFE\n",
    "\n",
    "# Specify locations of the train and (maybe) test networks.\n",
    "s.train_net = train_net_path\n",
    "\n",
    "s.test_net.append(test_net_path)\n",
    "s.test_iter.append(1) # Test on 100 batches each time we test.\n",
    "\n",
    "s.test_net.append(train_net_path_test_time)\n",
    "s.test_iter.append(1) # Test on 100 batches each time we test.\n",
    "\n",
    "\n",
    "s.test_interval = 1000000  # Test after every s.test_interval training iterations.\n",
    "\n",
    "\n",
    "s.max_iter = 10000     # no. of times to update the net (training iterations)\n",
    " \n",
    "# EDIT HERE to try different solvers\n",
    "# solver types include \"SGD\", \"Adam\", and \"Nesterov\" among others.\n",
    "s.type = \"Adam\"\n",
    "\n",
    "# Set the initial learning rate for SGD.\n",
    "s.base_lr = base_lr  # EDIT HERE to try different learning rates\n",
    "# Set momentum to accelerate learning by\n",
    "# taking weighted average of current and previous updates.\n",
    "s.momentum = 0.9\n",
    "# Set weight decay to regularize and prevent overfitting\n",
    "s.weight_decay = reg_param\n",
    "\n",
    "# Set `lr_policy` to define how the learning rate changes during training.\n",
    "# This is the same policy as our default LeNet.\n",
    "# http://stackoverflow.com/questions/30033096/what-is-lr-policy-in-caffe\n",
    "# // The learning rate decay policy. The currently implemented learning rate\n",
    "# // policies are as follows:\n",
    "# //    - fixed: always return base_lr.\n",
    "# //    - step: return base_lr * gamma ^ (floor(iter / step))\n",
    "# //    - exp: return base_lr * gamma ^ iter\n",
    "# //    - inv: return base_lr * (1 + gamma * iter) ^ (- power)\n",
    "# //    - multistep: similar to step but it allows non uniform steps defined by\n",
    "# //      stepvalue\n",
    "# //    - poly: the effective learning rate follows a polynomial decay, to be\n",
    "# //      zero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)\n",
    "# //    - sigmoid: the effective learning rate follows a sigmod decay\n",
    "# //      return base_lr ( 1/(1 + exp(-gamma * (iter - stepsize))))\n",
    "# //\n",
    "# // where base_lr, max_iter, gamma, step, stepvalue and power are defined\n",
    "# // in the solver parameter protocol buffer, and iter is the current iteration.\n",
    "s.lr_policy = 'fixed'\n",
    "s.gamma = gamma\n",
    "s.power = 0.75\n",
    "s.stepsize = stepsize\n",
    "# EDIT HERE to try the fixed rate (and compare with adaptive solvers)\n",
    "# `fixed` is the simplest policy that keeps the learning rate constant.\n",
    "# s.lr_policy = 'fixed'\n",
    "\n",
    "# Display the current training loss and accuracy every 1000 iterations.\n",
    "s.display = 2\n",
    "\n",
    "# Snapshots are files used to store networks we've trained.\n",
    "# We'll snapshot every 5K iterations -- twice during training.\n",
    "s.snapshot = 1000000\n",
    "s.snapshot_prefix = 'lenet_'\n",
    "\n",
    "s.snapshot_after_train = True\n",
    "\n",
    "# Train on the GPU\n",
    "s.solver_mode = caffe_pb2.SolverParameter.CPU\n",
    "\n",
    "\n",
    "solver_config_fname = 'lenet_solver' + train_suffix + '.prototxt'\n",
    "# Write the solver to a temporary file and return its filename.\n",
    "with open(solver_config_fname, 'w') as f:\n",
    "    f.write(str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 s, sys: 443 ms, total: 6.71 s\n",
      "Wall time: 8.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import h5py\n",
    "f = h5py.File('../data/train_data_lenet.hd5', 'w')\n",
    "f.create_dataset('data', data=X_train_clean_cv[0:td_size], compression='gzip', compression_opts=4)\n",
    "f.create_dataset('label', data=y_train_clean_cv[0:td_size], compression='gzip', compression_opts=4)\n",
    "f.close()\n",
    "\n",
    "f = h5py.File('../data/test_data_lenet.hd5', 'w')\n",
    "f.create_dataset('data', data=X_val_clean_cv, compression='gzip', compression_opts=4)\n",
    "f.create_dataset('label', data=y_val_clean_cv, compression='gzip', compression_opts=4)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "solver = None\n",
    "solver = caffe.get_solver(solver_config_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 1.61 s, total: 12 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "solver.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 18.3 ms, total: 2.83 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "solver.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 s, sys: 411 ms, total: 28 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "solver.step(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 0:\n",
    "    td_size = 1\n",
    "    f = h5py.File('../data/train_data_lenet.hd5', 'w')\n",
    "    f.create_dataset('data', data=X_train_clean_cv[0:td_size], compression='gzip', compression_opts=4)\n",
    "    f.create_dataset('label', data=y_train_clean_cv[0:td_size], compression='gzip', compression_opts=4)\n",
    "    f.close()\n",
    "\n",
    "    solver = None\n",
    "    solver = caffe.get_solver(solver_config_fname)\n",
    "\n",
    "    num_epochs = 100\n",
    "    num_iter_per_epoch = int(np.ceil(float(td_size) / batch_size))\n",
    "    niter = num_iter_per_epoch * num_epochs\n",
    "\n",
    "    #val_data_size = X_val_clean_cv.shape[0]\n",
    "    val_data_size = 4*batch_size\n",
    "\n",
    "    print \"td_size = %d\" % td_size\n",
    "    print \"niter = %d\" % niter\n",
    "\n",
    "    solver.step(niter)\n",
    "\n",
    "    train_error_check = solver.net.blobs['loss'].data\n",
    "\n",
    "    print \"testing...\"\n",
    "\n",
    "    val_error = 0\n",
    "    val_error_check = 0\n",
    "    niter_val = int(np.ceil( float(val_data_size) / batch_size))\n",
    "    for test_it in range(niter_val):\n",
    "        solver.test_nets[0].forward()\n",
    "        val_error += np.sum( (solver.test_nets[0].blobs['score'].data -\n",
    "                             solver.test_nets[0].blobs['label'].data) ** 2) / (2 * float(val_data_size))\n",
    "        val_error_check += solver.test_nets[0].blobs['loss'].data / niter_val\n",
    "\n",
    "\n",
    "    train_error = 0\n",
    "    for test_it in range(num_iter_per_epoch):\n",
    "        solver.test_nets[1].forward()\n",
    "        train_error += np.sum( (solver.test_nets[1].blobs['score'].data -\n",
    "                             solver.test_nets[1].blobs['label'].data) ** 2) / (2 * float(num_iter_per_epoch * batch_size))\n",
    "\n",
    "    print \"train_error = %f, train_error_check = %f, \\\n",
    "    val_error = %f, val_error_check = %f\" % \\\n",
    "            (train_error, train_error_check, val_error, val_error_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_loss(a, b):\n",
    "    batch_size, num_labels = a.shape\n",
    "    \n",
    "    return np.sum((a-b)**2) / float(batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(a, b):\n",
    "    batch_size, num_labels = a.shape\n",
    "    return np.sqrt( np.sum((a-b)**2) / float(batch_size * num_labels) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td_size = 1600\n",
      "niter = 250\n",
      "val_interval = 25\n",
      "it = 0, t_loss = 40040.27, t_error = 15399.49, v_error = 15886.62, t_rmse = 32.04, v_rmse = 32.54\n",
      "it = 25, t_loss = 665.08, t_error = 476.46, v_error = 477.53, t_rmse = 5.64, v_rmse = 5.64\n",
      "it = 50, t_loss = 275.62, t_error = 180.70, v_error = 189.67, t_rmse = 3.47, v_rmse = 3.56\n",
      "it = 75, t_loss = 189.43, t_error = 129.97, v_error = 123.39, t_rmse = 2.94, v_rmse = 2.87\n",
      "it = 100, t_loss = 174.52, t_error = 111.90, v_error = 99.44, t_rmse = 2.73, v_rmse = 2.57\n",
      "it = 125, t_loss = 163.15, t_error = 86.77, v_error = 105.67, t_rmse = 2.41, v_rmse = 2.65\n",
      "it = 150, t_loss = 154.38, t_error = 74.28, v_error = 105.60, t_rmse = 2.23, v_rmse = 2.65\n",
      "it = 175, t_loss = 149.70, t_error = 57.58, v_error = 88.68, t_rmse = 1.96, v_rmse = 2.43\n",
      "it = 200, t_loss = 139.53, t_error = 58.80, v_error = 68.80, t_rmse = 1.98, v_rmse = 2.14\n",
      "it = 225, t_loss = 138.77, t_error = 65.68, v_error = 84.72, t_rmse = 2.09, v_rmse = 2.38\n",
      "it = 249, t_loss = 105.28, t_error = 92.21, v_error = 104.13, t_rmse = 2.48, v_rmse = 2.63\n",
      "CPU times: user 13min 59s, sys: 12.3 s, total: 14min 11s\n",
      "Wall time: 7min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f = h5py.File('../data/train_data_lenet.hd5', 'w')\n",
    "f.create_dataset('data', data=X_train_clean_cv[0:td_size], compression='gzip', compression_opts=4)\n",
    "f.create_dataset('label', data=y_train_clean_cv[0:td_size], compression='gzip', compression_opts=4)\n",
    "f.close()\n",
    "\n",
    "solver = None\n",
    "solver = caffe.get_solver(solver_config_fname)\n",
    "\n",
    "\n",
    "num_iter_per_epoch = int(np.ceil(float(td_size) / batch_size))\n",
    "niter = num_iter_per_epoch * num_epochs\n",
    "val_interval = num_iter_per_epoch\n",
    "\n",
    "\n",
    "# niter_val_error = int(np.ceil( float(val_data_size) / batch_size))\n",
    "niter_val_error = 2 \n",
    "niter_train_error = 2 \n",
    "\n",
    "print \"td_size = %d\" % td_size\n",
    "print \"niter = %d\" % niter\n",
    "print \"val_interval = %d\" % val_interval\n",
    "train_loss = np.zeros(niter)\n",
    "train_error = np.zeros( int(np.ceil(float(niter) / val_interval)))\n",
    "val_error = np.zeros( int(np.ceil(float(niter) / val_interval)))\n",
    "train_rmse = np.zeros( int(np.ceil(float(niter) / val_interval)))\n",
    "val_rmse = np.zeros( int(np.ceil(float(niter) / val_interval)))\n",
    "\n",
    "\n",
    "conv1_out = []\n",
    "conv1_weights = []\n",
    "conv1_biases = []\n",
    "conv1_weights_diff = []\n",
    "conv1_biases_diff = []\n",
    "\n",
    "conv2_out = []\n",
    "conv2_weights = []\n",
    "conv2_biases = []\n",
    "conv2_weights_diff = []\n",
    "conv2_biases_diff = []\n",
    "\n",
    "\n",
    "fc1_weights = []\n",
    "fc1_biases = []\n",
    "fc1_weights_diff = []\n",
    "fc1_biases_diff = []\n",
    "\n",
    "score_weights = []\n",
    "score_biases = []\n",
    "score_weights_diff = []\n",
    "score_biases_diff = []\n",
    "\n",
    "out_score = []\n",
    "\n",
    "for it in range(niter):\n",
    "    solver.step(1)\n",
    "    \n",
    "    train_loss[it] = solver.net.blobs['loss'].data\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if (it % val_interval) == 0 or (it == niter - 1):\n",
    "        \n",
    "        if DEBUG_MSGS:\n",
    "        \n",
    "            conv1_out.append(solver.net.blobs['conv1'].data.copy())\n",
    "            conv2_out.append(solver.net.blobs['conv2'].data.copy())\n",
    "            out_score.append(solver.net.blobs['score'].data.copy())\n",
    "\n",
    "            score_weights.append(solver.net.params['score'][0].data.copy())\n",
    "            score_biases.append(solver.net.params['score'][1].data.copy())\n",
    "            score_weights_diff.append(solver.net.params['score'][0].diff.copy())\n",
    "            score_biases_diff.append(solver.net.params['score'][1].diff.copy())\n",
    "\n",
    "            conv1_weights.append(solver.net.params['conv1'][0].data.copy())\n",
    "            conv1_biases.append(solver.net.params['conv1'][1].data.copy())\n",
    "            conv1_weights_diff.append(solver.net.params['conv1'][0].diff.copy())\n",
    "            conv1_biases_diff.append(solver.net.params['conv1'][1].diff.copy())\n",
    "\n",
    "            conv2_weights.append(solver.net.params['conv2'][0].data.copy())\n",
    "            conv2_biases.append(solver.net.params['conv2'][1].data.copy())\n",
    "            conv2_weights_diff.append(solver.net.params['conv2'][0].diff.copy())\n",
    "            conv2_biases_diff.append(solver.net.params['conv2'][1].diff.copy())\n",
    "\n",
    "            fc1_weights.append(solver.net.params['fc1'][0].data.copy())\n",
    "            fc1_biases.append(solver.net.params['fc1'][1].data.copy())\n",
    "            fc1_weights_diff.append(solver.net.params['fc1'][0].diff.copy())\n",
    "            fc1_biases_diff.append(solver.net.params['fc1'][1].diff.copy())\n",
    "\n",
    "            score_weights.append(solver.net.params['score'][0].data.copy())\n",
    "            score_biases.append(solver.net.params['score'][1].data.copy())\n",
    "            score_weights_diff.append(solver.net.params['score'][0].diff.copy())\n",
    "            score_biases_diff.append(solver.net.params['score'][1].diff.copy())\n",
    "        \n",
    "        \n",
    "        val_error2_cum = 0\n",
    "        for test_it in range(niter_val_error):\n",
    "            solver.test_nets[0].forward()\n",
    "            val_error2_cum += np.sum ( (solver.test_nets[0].blobs['score'].data - \\\n",
    "                                        solver.test_nets[0].blobs['label'].data) ** 2)\n",
    "        val_error[it // val_interval] = val_error2_cum / (2 * batch_size * niter_val_error)\n",
    "        val_rmse[it // val_interval] = np.sqrt( val_error2_cum / (batch_size * niter_val_error * num_labels))\n",
    "        \n",
    "        train_error2_cum = 0\n",
    "        for test_it in range(niter_train_error):\n",
    "            solver.test_nets[1].forward()\n",
    "            train_error2_cum += np.sum( (solver.test_nets[1].blobs['score'].data - \\\n",
    "                                         solver.test_nets[1].blobs['label'].data) ** 2 )\n",
    "        train_error[it // val_interval] = train_error2_cum / (2 * batch_size * niter_val_error)\n",
    "        train_rmse[it // val_interval] = np.sqrt( train_error2_cum / (batch_size * niter_val_error * num_labels))\n",
    "        \n",
    "        \n",
    "        print \"it = %d, t_loss = %.02f, t_error = %.02f, v_error = %.02f, t_rmse = %.02f, v_rmse = %.02f\" % \\\n",
    "        (it, train_loss[it], \\\n",
    "         train_error[it // val_interval], val_error[it // val_interval], \\\n",
    "         train_rmse[it // val_interval], val_rmse[it // val_interval])\n",
    "        \n",
    "#         _, ax1 = plt.subplots()\n",
    "#         # ax2 = ax1.twinx()\n",
    "#         ax1.plot(range(niter), train_loss, 'k', label='train_loss')\n",
    "#         ax1.plot(val_interval * np.arange(len(val_error)), val_error, 'r', label='val_error')\n",
    "#         ax1.plot(val_interval * np.arange(len(train_error)), train_error, 'b', label='train_error')\n",
    "#         ax1.legend()\n",
    "#         ax1.set_xlabel('iteration')\n",
    "#         ax1.set_ylabel('error')\n",
    "#         ax1.set_ylim([0,1000])\n",
    "        \n",
    "        if (auto_stop == True) and (it >= min_epochs * batch_size):\n",
    "            val_it = it // val_interval\n",
    "            train_error_10 = train_error[val_it - 10: val_it]\n",
    "            mean_diff_10 = np.mean(np.diff(train_error_10))\n",
    "            if np.abs(mean_diff_10) < 5:\n",
    "                print \"mean_diff_10 = \", mean_diff_10\n",
    "                break\n",
    "\n",
    "solver.net.save('lenet_trained' + train_suffix + '.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAF5CAYAAACBThBWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRwsYpZRSSjU4/w8nLuwVJHKtVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f022a5fd190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax1 = plt.subplots()\n",
    "# ax2 = ax1.twinx()\n",
    "ax1.plot(range(niter), train_loss, 'k', label='train_loss')\n",
    "ax1.plot(val_interval * np.arange(len(val_error)), val_error, 'r', label='val_error')\n",
    "ax1.plot(val_interval * np.arange(len(train_error)), train_error, 'b', label='train_error')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('error')\n",
    "ax1.set_ylim([0,5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAFkCAYAAABMyWOlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f021151ca50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine training auto stop \n",
    "\n",
    "mean_10 = np.zeros_like(train_error)\n",
    "std_10 = np.zeros_like(train_error)\n",
    "mean_diff_10 = np.zeros_like(train_error)\n",
    "\n",
    "for idx in range(10, len(train_error)):\n",
    "    train_error_10 = train_error[idx-10:idx]\n",
    "    mean_10[idx] = np.mean(train_error_10)\n",
    "    std_10[idx] = np.std(train_error_10)\n",
    "    mean_diff_10[idx] = np.abs(np.mean(np.diff(train_error_10)))\n",
    "\n",
    "plt.plot(range(len(train_error)), mean_10, color='b')\n",
    "plt.plot(range(len(train_error)), std_10, color='r')\n",
    "plt.plot(range(len(train_error)), mean_diff_10, color='k')\n",
    "plt.ylim([-10, 10])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_error = 92.206810, val_error = 104.133469\n"
     ]
    }
   ],
   "source": [
    "print \"training_error = %f, val_error = %f\" % (train_error[-1], val_error[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    additional_epochs = 25\n",
    "    addn_niter = num_iter_per_epoch * additional_epochs\n",
    "    train_loss_2 = np.append(train_loss, np.zeros(addn_niter))\n",
    "    train_error_2 = np.append(train_error, np.zeros(int(np.ceil(float(addn_niter) / val_interval))))\n",
    "    val_error_2 = np.append(val_error, np.zeros(int(np.ceil(float(addn_niter) / val_interval))))\n",
    "\n",
    "    print \"niter = \", niter\n",
    "    print \"addn_niter = \", addn_niter\n",
    "\n",
    "    for it in range(niter, niter + addn_niter):\n",
    "        solver.step(1)\n",
    "\n",
    "        train_loss_2[it] = solver.net.blobs['loss'].data\n",
    "            \n",
    "        if (it % val_interval) == 0:\n",
    "\n",
    "            val_error_this = 0\n",
    "            for test_it in range(niter_val_error):\n",
    "                solver.test_nets[0].forward()\n",
    "                val_error_this += euclidean_loss(solver.test_nets[0].blobs['score'].data , \n",
    "                                                 solver.test_nets[0].blobs['label'].data) / niter_val_error\n",
    "            val_error_2[it // val_interval] = val_error_this\n",
    "\n",
    "            train_error_this = 0\n",
    "            for test_it in range(niter_train_error):\n",
    "                solver.test_nets[1].forward()\n",
    "                train_error_this += euclidean_loss(solver.test_nets[1].blobs['score'].data , \n",
    "                                                 solver.test_nets[1].blobs['label'].data) / niter_train_error\n",
    "            train_error_2[it // val_interval] = train_error_this\n",
    "\n",
    "\n",
    "            print \"addn_iter = %d, train_loss = %f, train_error = %f, val_error = %f\" % (it, train_loss_2[it], train_error_2[it // val_interval], val_error_2[it // val_interval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    _, ax1 = plt.subplots()\n",
    "    # ax2 = ax1.twinx()\n",
    "    ax1.plot(val_interval * np.arange(len(val_error_2)), train_error_2, label='train_error')\n",
    "    ax1.plot(val_interval * np.arange(len(val_error_2)), val_error_2, 'r', label='val_error')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel('iteration')\n",
    "    ax1.set_ylabel('error')\n",
    "    ax1.set_ylim([0,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "(64, 1, 96, 96)\n",
      "[[ -34.84467316  -35.84467316  -38.84467316  -36.84467316  -34.84467316]\n",
      " [-122.84467316 -122.84467316 -122.84467316 -122.84467316 -121.84467316]\n",
      " [ -77.84467316  -75.84467316  -82.84467316  -83.84467316  -78.84467316]\n",
      " [ 101.15532684  100.15532684  102.15532684   99.15532684   98.15532684]\n",
      " [ -55.84467316  -55.84467316  -56.84467316  -55.84467316  -55.84467316]]\n",
      "conv1\n",
      "(64, 32, 94, 94)\n",
      "[[ -8.67767429  -8.45171642  -8.65324306 -10.48230362 -13.00982761]\n",
      " [-12.36353493 -12.64729881 -12.80599117 -13.06064224 -12.70764637]\n",
      " [-10.28796768  -9.72138691  -7.55021954  -8.64352989  -9.55505276]\n",
      " [  9.41055965   8.06610584   8.80013943  10.26618671  10.20266342]\n",
      " [ -1.85146761  -2.66858912  -2.10037661  -0.50663185  -1.89532852]]\n",
      "relu1\n",
      "(64, 32, 94, 94)\n",
      "[[ -0.86776745  -0.84517163  -0.86532432  -1.04823041  -1.30098283]\n",
      " [ -1.23635352  -1.26472986  -1.28059912  -1.30606425  -1.27076471]\n",
      " [ -1.02879679  -0.9721387   -0.75502199  -0.864353    -0.95550531]\n",
      " [  9.41055965   8.06610584   8.80013943  10.26618671  10.20266342]\n",
      " [ -0.18514676  -0.26685891  -0.21003766  -0.05066318  -0.18953286]]\n",
      "pool1\n",
      "(64, 32, 47, 47)\n",
      "[[ -0.84517163  -0.86532432  -0.76361674  -0.8379184   -0.98785126]\n",
      " [ -1.18860674  -1.13278091  -1.01794326  -0.9078173   -0.70988446]\n",
      " [ -0.81026745  -0.73591673  -0.71391171  -0.90227693  -0.92976332]\n",
      " [  9.41055965  10.26618671  10.20266342   8.64453697   8.98790646]\n",
      " [ -0.18514676  -0.05066318  -0.18953286  -0.181215    -0.11959868]]\n",
      "conv2\n",
      "(64, 64, 45, 45)\n",
      "[[ 1.34957445  1.71589696  1.69113564  1.53511298  1.60968161]\n",
      " [ 2.85945082  2.61138082  2.30296969  2.19320869  1.95957661]\n",
      " [ 2.17270041  2.08335567  2.09759355  2.12264276  2.00700617]\n",
      " [-0.47219917  0.35809129  0.86694109  1.12784147  0.52039301]\n",
      " [ 1.24919307  1.55383241  1.26440918  1.18039787  1.24790525]]\n",
      "relu2\n",
      "(64, 64, 45, 45)\n",
      "[[ 1.34957445  1.71589696  1.69113564  1.53511298  1.60968161]\n",
      " [ 2.85945082  2.61138082  2.30296969  2.19320869  1.95957661]\n",
      " [ 2.17270041  2.08335567  2.09759355  2.12264276  2.00700617]\n",
      " [-0.04721992  0.35809129  0.86694109  1.12784147  0.52039301]\n",
      " [ 1.24919307  1.55383241  1.26440918  1.18039787  1.24790525]]\n",
      "pool2\n",
      "(64, 64, 23, 23)\n",
      "[[ 0.          3.56820798  0.          2.91495419  0.        ]\n",
      " [ 5.71890163  0.          0.          0.          4.86335421]\n",
      " [ 4.34540081  4.61088753  0.          4.48936987  4.42493296]\n",
      " [ 4.44265747  0.          0.          0.          2.23906398]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "fc1\n",
      "[[ -3.43218017  25.6625576   -5.14003181  24.5368557   33.20808411]\n",
      " [ -3.61181426  30.87041473  -5.96944714  27.10666466  35.77092361]]\n",
      "score\n",
      "[[ 64.00341034  34.18983078  28.68016815  34.43842697  56.82823563\n",
      "   35.74072647  72.22235107  35.17377472  35.37472153  35.50140381\n",
      "   20.12477112  36.04698563  53.57611465  26.9817543   77.4852829\n",
      "   25.0193615   37.1593399   29.00806999  14.25097847  29.04617882\n",
      "   48.11552429  58.09522629  62.94672775  75.41278839  34.9940834\n",
      "   76.19560242  48.97822571  74.56088257  47.91163635  80.67575073]\n",
      " [ 66.6124649   38.54575348  32.00198746  39.92029953  59.9706459\n",
      "   41.14725876  74.23186493  41.31308746  40.7378006   40.41737366\n",
      "   23.575634    41.07038116  57.88110733  34.35329056  78.88330841\n",
      "   30.86843681  43.03623962  33.5464859   16.49866486  35.13773727\n",
      "   55.01660156  61.49524307  66.54730225  79.11761475  35.49694443\n",
      "   80.21135712  52.28740692  78.99849701  52.62285614  84.94514465]]\n",
      "conv1 weights\n",
      "(32, 1, 3, 3)\n",
      "[[[[-0.09885646  0.02636219  0.04333087]\n",
      "   [ 0.08196104 -0.28376636  0.08444813]\n",
      "   [ 0.06300349 -0.03160352  0.21645267]]]\n",
      "\n",
      "\n",
      " [[[-0.50899971 -0.10611302  0.51173937]\n",
      "   [-0.57670623 -0.44658038  0.15868717]\n",
      "   [ 0.43803737  0.42594132 -0.28011927]]]]\n",
      "conv1 biases\n",
      "(32,)\n",
      "[ 0.11617181  0.10803324  0.09724724  0.11924291  0.10940892]\n",
      "conv2 weights\n",
      "(64, 32, 3, 3)\n",
      "[[[-0.09029206 -0.07719597  0.00373228]\n",
      "  [-0.07462613 -0.0740629  -0.02233401]]\n",
      "\n",
      " [[ 0.03865611 -0.05138649 -0.05859065]\n",
      "  [-0.09670312 -0.03446488  0.0162861 ]]]\n",
      "conv2 biases\n",
      "(64,)\n",
      "[ 0.09825484  0.10017933  0.09681229  0.09828104  0.10120516]\n",
      "fc1 weights\n",
      "(500, 33856)\n",
      "[[ -6.45348150e-03  -7.00539537e-03  -7.93316588e-03  -1.47754292e-03\n",
      "   -1.07619585e-02]\n",
      " [ -2.07706820e-03  -6.62120947e-05   4.10554046e-03   1.05844503e-02\n",
      "    5.51289180e-03]\n",
      " [ -1.12997936e-02   8.49991920e-04  -3.57587612e-03  -8.94666463e-03\n",
      "    1.06333417e-03]\n",
      " [ -6.08409522e-03  -7.44074257e-03  -4.91499435e-03  -6.71047252e-03\n",
      "   -4.30618506e-03]\n",
      " [ -6.44887425e-03   1.65034042e-04   6.82459446e-03   8.80773459e-03\n",
      "    3.38416384e-03]]\n",
      "fc1 biases\n",
      "(500,)\n",
      "[ 0.09806336  0.10164573  0.09639733  0.10337769  0.10338131]\n",
      "score weights\n",
      "(30, 500)\n",
      "[[ 0.00043049 -0.05359796 -0.00628462 -0.00901859 -0.07353286]\n",
      " [ 0.05744135 -0.00455399  0.06995793  0.04727857  0.04055869]\n",
      " [-0.03322715 -0.0341415   0.07087635 -0.03326331  0.03760117]\n",
      " [-0.06988229 -0.00693986 -0.06848771 -0.0031381   0.0751847 ]\n",
      " [ 0.04333419  0.01933183  0.00512597  0.03659466 -0.00734114]]\n",
      "score biases\n",
      "(30,)\n",
      "[ 0.00470867  0.00222127  0.00431708  0.00421848  0.00414714]\n",
      "diffs\n",
      "conv1 weights\n",
      "(32, 1, 3, 3)\n",
      "[[[[  7.59452669e-05   7.31170003e-05   7.28241212e-05]\n",
      "   [  6.96887728e-05   6.65080661e-05   6.81139209e-05]\n",
      "   [  6.58697900e-05   6.33047894e-05   6.59942525e-05]]]\n",
      "\n",
      "\n",
      " [[[  8.77935418e-06   3.64795801e-06   1.71360023e-06]\n",
      "   [  8.53026813e-06   3.95513189e-06   1.10883673e-06]\n",
      "   [  1.05049994e-05   7.48943512e-06   2.36325741e-06]]]]\n",
      "conv1 biases\n",
      "(32,)\n",
      "[  1.65985193e-06  -7.74934233e-05  -4.07364132e-05  -8.18619083e-05\n",
      "  -6.87023276e-05]\n",
      "conv2 weights\n",
      "(64, 32, 3, 3)\n",
      "[[[ -1.29065447e-05  -1.28590573e-05  -1.76356862e-05]\n",
      "  [  8.01522128e-06   1.53623569e-06  -3.17522540e-06]]\n",
      "\n",
      " [[ -2.39864621e-05  -2.48442266e-05  -2.70169712e-05]\n",
      "  [  1.90543906e-05   1.99546139e-05   2.02818592e-05]]]\n",
      "conv2 biases\n",
      "(64,)\n",
      "[ -6.38172423e-06  -1.75949826e-05  -7.06096716e-06  -1.07802925e-05\n",
      "  -2.10827184e-05]\n",
      "fc1 weights\n",
      "(500, 33856)\n",
      "[[  7.10723839e-07  -1.15922865e-06  -1.05712888e-06  -5.59838281e-06\n",
      "    6.70713507e-06]\n",
      " [  9.03264754e-06  -1.32631467e-05  -5.29930294e-05   2.41025009e-05\n",
      "   -4.89181948e-05]\n",
      " [ -1.18731978e-05   1.89878847e-06   1.26640566e-06  -7.34068135e-06\n",
      "   -1.08673350e-06]\n",
      " [ -5.85536782e-06  -1.30630187e-05  -9.51666334e-06  -1.06876678e-05\n",
      "    4.28179504e-07]\n",
      " [ -1.17800128e-05   7.83572705e-06  -1.50971255e-05  -2.05226879e-05\n",
      "    8.60654836e-06]]\n",
      "fc1 biases\n",
      "(500,)\n",
      "[  1.12653026e-06  -2.25506647e-05  -9.04801880e-07  -1.24644703e-05\n",
      "  -1.52525206e-06]\n",
      "score weights\n",
      "(30, 500)\n",
      "[[  2.67540035e-08   4.15766090e-06  -1.89663740e-06   1.69447230e-06\n",
      "    7.85383747e-07]\n",
      " [  5.28068404e-06  -1.40947368e-05   1.95290304e-05  -1.23470718e-05\n",
      "   -1.50020751e-05]\n",
      " [  3.19337505e-06  -1.17335749e-05   1.23147620e-05  -6.77420803e-06\n",
      "   -8.02850627e-06]\n",
      " [ -7.62299692e-07   3.61880120e-06  -3.86379725e-06   2.49105346e-06\n",
      "    2.48572496e-06]\n",
      " [ -2.35778970e-07   4.06379877e-06  -2.10028111e-06   1.55101543e-06\n",
      "    1.54819509e-06]]\n",
      "score biases\n",
      "(30,)\n",
      "[ -3.97621898e-06  -1.59931133e-05  -1.01342521e-05  -8.32696173e-07\n",
      "  -2.83600366e-06]\n",
      "129.847432413\n"
     ]
    }
   ],
   "source": [
    "my_net = solver.net\n",
    "train_error_sanity = 0\n",
    "niter_sanity = 1\n",
    "batch_size_used = 128\n",
    "for it in range(niter_sanity):\n",
    "    it_range = range(it*batch_size, it*batch_size+batch_size)\n",
    "    my_net.blobs['data'].data[...] = X_train_clean_cv[it_range]\n",
    "    my_net.forward()\n",
    "    out = my_net.blobs['score'].data\n",
    "    \n",
    "    net = my_net\n",
    "    \n",
    "    print \"data\"\n",
    "    print net.blobs['data'].data.shape\n",
    "    print net.blobs['data'].data[0:5, 0, 0:5, 0]\n",
    "    \n",
    "    print \"conv1\"\n",
    "    print net.blobs['conv1'].data.shape\n",
    "    print net.blobs['conv1'].data[0:5, 0, 0:5, 0]\n",
    "    \n",
    "    print \"relu1\"\n",
    "    print net.blobs['relu1'].data.shape\n",
    "    print net.blobs['relu1'].data[0:5, 0, 0:5, 0]\n",
    "    \n",
    "    print \"pool1\"\n",
    "    print net.blobs['pool1'].data.shape\n",
    "    print net.blobs['pool1'].data[0:5, 0, 0:5, 0]\n",
    "    \n",
    "    \n",
    "    print \"conv2\"\n",
    "    print net.blobs['conv2'].data.shape\n",
    "    print net.blobs['conv2'].data[0:5, 0, 0:5, 0]\n",
    "    \n",
    "    print \"relu2\"\n",
    "    print net.blobs['relu2'].data.shape\n",
    "    print net.blobs['relu2'].data[0:5, 0, 0:5, 0]\n",
    "    \n",
    "    print \"pool2\"\n",
    "    print net.blobs['pool2'].data.shape\n",
    "    print net.blobs['pool2'].data[0:5, 0, 0:5, 0]\n",
    "    \n",
    "    print \"fc1\"\n",
    "    print net.blobs['fc1'].data[0:2,0:5]\n",
    "    \n",
    "    print \"score\"\n",
    "    print net.blobs['score'].data[0:2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print \"conv1 weights\"\n",
    "    print net.params['conv1'][0].data.shape\n",
    "    print net.params['conv1'][0].data[0:2][0:5]\n",
    "    \n",
    "    print \"conv1 biases\"\n",
    "    print net.params['conv1'][1].data.shape\n",
    "    print net.params['conv1'][1].data[0:5]\n",
    "    \n",
    "    print \"conv2 weights\"\n",
    "    print net.params['conv2'][0].data.shape\n",
    "    print net.params['conv2'][0].data[0:2, 0:2, 0:5, 0]\n",
    "    \n",
    "    print \"conv2 biases\"\n",
    "    print net.params['conv2'][1].data.shape\n",
    "    print net.params['conv2'][1].data[0:5]\n",
    "    \n",
    "    print \"fc1 weights\"\n",
    "    print net.params['fc1'][0].data.shape\n",
    "    print net.params['fc1'][0].data[0:5, 0:5]\n",
    "    \n",
    "    print \"fc1 biases\"\n",
    "    print net.params['fc1'][1].data.shape\n",
    "    print net.params['fc1'][1].data[0:5]\n",
    "    \n",
    "    print \"score weights\"\n",
    "    print net.params['score'][0].data.shape\n",
    "    print net.params['score'][0].data[0:5, 0:5]\n",
    "    \n",
    "    print \"score biases\"\n",
    "    print net.params['score'][1].data.shape\n",
    "    print net.params['score'][1].data[0:5]\n",
    "    \n",
    "    \n",
    "    print \"diffs\"\n",
    "    print \"conv1 weights\"\n",
    "    print net.params['conv1'][0].diff.shape\n",
    "    print net.params['conv1'][0].diff[0:2][0:5]\n",
    "    \n",
    "    print \"conv1 biases\"\n",
    "    print net.params['conv1'][1].diff.shape\n",
    "    print net.params['conv1'][1].diff[0:5]\n",
    "    \n",
    "    print \"conv2 weights\"\n",
    "    print net.params['conv2'][0].diff.shape\n",
    "    print net.params['conv2'][0].diff[0:2, 0:2, 0:5, 0]\n",
    "    \n",
    "    print \"conv2 biases\"\n",
    "    print net.params['conv2'][1].diff.shape\n",
    "    print net.params['conv2'][1].diff[0:5]\n",
    "    \n",
    "    print \"fc1 weights\"\n",
    "    print net.params['fc1'][0].diff.shape\n",
    "    print net.params['fc1'][0].diff[0:5, 0:5]\n",
    "    \n",
    "    print \"fc1 biases\"\n",
    "    print net.params['fc1'][1].diff.shape\n",
    "    print net.params['fc1'][1].diff[0:5]\n",
    "    \n",
    "    print \"score weights\"\n",
    "    print net.params['score'][0].diff.shape\n",
    "    print net.params['score'][0].diff[0:5, 0:5]\n",
    "    \n",
    "    print \"score biases\"\n",
    "    print net.params['score'][1].diff.shape\n",
    "    print net.params['score'][1].diff[0:5]\n",
    "    \n",
    "#     print \"loss\"\n",
    "#     print net.params['loss'][0].diff.shape\n",
    "#     print net.params['loss'][0].diff[0:5]\n",
    "    \n",
    "#     train_error += np.sum( (out - y_train_clean_cv[it_range]) ** 2) / float(2* y_train_clean_cv.shape[1])\n",
    "    train_error_sanity += euclidean_loss(out, y_train_clean_cv[it_range])\n",
    "train_error_sanity = train_error_sanity / float(niter_sanity)  \n",
    "\n",
    "print train_error_sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282.409269343\n"
     ]
    }
   ],
   "source": [
    "val_error_sanity = 0\n",
    "niter_sanity = 8\n",
    "batch_size_used = 64\n",
    "for it in range(niter_sanity):\n",
    "    it_range = range(it*batch_size, it*batch_size+batch_size)\n",
    "    my_net.blobs['data'].data[...] = X_val_clean_cv[it_range]\n",
    "    my_net.forward()\n",
    "    out = my_net.blobs['score'].data\n",
    "    \n",
    "#     train_error += np.sum( (out - y_train_clean_cv[it_range]) ** 2) / float(2* y_train_clean_cv.shape[1])\n",
    "    val_error_sanity += euclidean_loss(out, y_val_clean_cv[it_range])\n",
    "val_error_sanity = val_error_sanity / float(niter_sanity)\n",
    "\n",
    "print val_error_sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280.828094064 4.32687796657\n"
     ]
    }
   ],
   "source": [
    "val_error2_cum = 0\n",
    "niter_val_error = 8\n",
    "batch_size_used = 64\n",
    "for it in range(niter_val_error):\n",
    "    it_range = range(it*batch_size, it*batch_size+batch_size)\n",
    "    solver.test_nets[0].forward()\n",
    "    val_error2_cum += np.sum ( (solver.test_nets[0].blobs['score'].data - \\\n",
    "                                y_val_clean_cv[it_range]) ** 2)\n",
    "val_error_2 = val_error2_cum / (2 * batch_size * niter_val_error)\n",
    "val_rmse_2 = np.sqrt( val_error2_cum / (batch_size * niter_val_error * num_labels))\n",
    "print val_error_2, val_rmse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 65.2167511   26.24515724  50.1937027 ]\n",
      " [ 67.38344574  21.22979164  49.13607407]\n",
      " [ 62.17735672  20.93436813  46.08032227]\n",
      " [ 69.27864838  19.94474411  51.92814255]\n",
      " [ 66.71883392  20.06941223  50.43896866]\n",
      " [ 66.46002197  22.31872559  53.9905014 ]\n",
      " [ 68.32492828  23.70261002  56.48256683]\n",
      " [ 65.18767548  25.73139954  50.56457138]]\n",
      "95.8252204358\n"
     ]
    }
   ],
   "source": [
    "val_error_sanity = 0\n",
    "niter_sanity = 8\n",
    "batch_size_used = 64\n",
    "for it in range(niter_sanity):\n",
    "    it_range = range(it*batch_size, it*batch_size+batch_size)\n",
    "    solver.test_nets[0].blobs['data'].data[...] = X_val_clean_cv[it_range]\n",
    "    solver.test_nets[0].forward(start='conv1')\n",
    "    out = solver.test_nets[0].blobs['score'].data\n",
    "    \n",
    "#     train_error += np.sum( (out - y_train_clean_cv[it_range]) ** 2) / float(2* y_train_clean_cv.shape[1])\n",
    "    val_error_sanity += np.sum ( (out - y_val_clean_cv[it_range]) ** 2)\n",
    "\n",
    "print out[0:64:8, 0:30:10]\n",
    "val_error_sanity = val_error_sanity / float(niter_sanity * 2 * batch_size_used)\n",
    "\n",
    "print val_error_sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if DEBUG_MSGS:\n",
    "    print len(conv1_out)\n",
    "    print conv1_out[0].shape\n",
    "\n",
    "    for i in range(5):\n",
    "        conv1_out_i = conv1_out[i]\n",
    "        print conv1_out_i[0:5, 0, 0:5, 0]\n",
    "\n",
    "    print len(conv2_out)\n",
    "    print conv2_out[0].shape\n",
    "\n",
    "    for i in range(5):\n",
    "        conv2_out_i = conv2_out[i]\n",
    "        print conv2_out_i[0:5, 0, 0:5, 0]\n",
    "\n",
    "    print \"conv1 weights and biases\"\n",
    "    print len(conv1_weights)\n",
    "    print conv1_weights[0].shape\n",
    "    for i in range(5):\n",
    "        conv1_weights_i = conv1_weights[i]\n",
    "        print conv1_weights_i[0:2,0,0:2,0]\n",
    "\n",
    "    print len(conv1_biases)\n",
    "    print conv1_biases[0].shape\n",
    "    for i in range(5):\n",
    "        conv1_biases_i = conv1_biases[i]\n",
    "        print conv1_biases_i[0:5]\n",
    "\n",
    "    print \"diff conv1 weights and biases\"\n",
    "    print len(conv1_weights_diff)\n",
    "    print conv1_weights_diff[0].shape\n",
    "    for i in range(5):\n",
    "        conv1_weights_i = conv1_weights_diff[i]\n",
    "        print conv1_weights_i[0:2,0,0:2,0]\n",
    "\n",
    "    print len(conv1_biases_diff)\n",
    "    print conv1_biases_diff[0].shape\n",
    "    for i in range(5):\n",
    "        conv1_biases_i = conv1_biases_diff[i]\n",
    "        print conv1_biases_i[0:5]\n",
    "\n",
    "    print \"conv2 weights and biases\"\n",
    "    print len(conv2_weights)\n",
    "    print conv2_weights[0].shape\n",
    "    for i in range(5):\n",
    "        conv2_weights_i = conv2_weights[i]\n",
    "        print conv2_weights_i[0:2,0,0:2,0]\n",
    "\n",
    "    print len(conv2_biases)\n",
    "    print conv2_biases[0].shape\n",
    "    for i in range(5):\n",
    "        conv2_biases_i = conv2_biases[i]\n",
    "        print conv2_biases_i[0:5]\n",
    "\n",
    "    print len(conv2_weights_diff)\n",
    "    print conv2_weights_diff[0].shape\n",
    "    for i in range(5):\n",
    "        conv2_weights_i = conv2_weights_diff[i]\n",
    "        print conv2_weights_i[0:2,0,0:2,0]\n",
    "\n",
    "    print \"diff conv2 weights and biases\"\n",
    "    print len(conv2_biases_diff)\n",
    "    print conv2_biases_diff[0].shape\n",
    "    for i in range(5):\n",
    "        conv2_biases_i = conv2_biases_diff[i]\n",
    "        print conv2_biases_i[0:5]\n",
    "\n",
    "    print len(fc1_weights_diff)\n",
    "    print fc1_weights_diff[0].shape\n",
    "    for i in range(5):\n",
    "        fc1_weights_i = fc1_weights_diff[i]\n",
    "        print fc1_weights_i[0:2,0:5]\n",
    "\n",
    "    print len(fc1_biases_diff)\n",
    "    print fc1_biases_diff[0].shape\n",
    "    for i in range(5):\n",
    "        fc1_biases_i = fc1_biases_diff[i]\n",
    "        print fc1_biases_i[0:5]\n",
    "\n",
    "    print len(score_weights)\n",
    "    print score_weights[0].shape\n",
    "    for i in range(5):\n",
    "        score_weights_i = score_weights[i]\n",
    "        print score_weights_i[0:30:10,0]\n",
    "\n",
    "    print len(score_biases)\n",
    "    print score_biases_diff[0].shape\n",
    "    for i in range(5):\n",
    "        score_biases_i = score_biases[i]\n",
    "        print score_biases_i[0:30:6]\n",
    "\n",
    "    print len(score_weights_diff)\n",
    "    print score_weights_diff[0].shape\n",
    "    for i in range(5):\n",
    "        score_weights_i = score_weights_diff[i]\n",
    "        print score_weights_i[0:30:10,0]\n",
    "\n",
    "    print len(score_biases_diff)\n",
    "    print score_biases_diff[0].shape\n",
    "    for i in range(5):\n",
    "        score_biases_i = score_biases_diff[i]\n",
    "        print score_biases_i[0:30:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
